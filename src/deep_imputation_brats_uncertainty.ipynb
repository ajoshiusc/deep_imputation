{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLtiAWdGKX7J"
      },
      "source": [
        "# Deep Imputation of BraTS dataset with MONAI\n",
        "\n",
        "The dataset comes from http://medicaldecathlon.com/.  \n",
        "Modality: Multimodal multisite MRI data (FLAIR, T1w, T1gd,T2w)  \n",
        "Size: 750 4D volumes (484 Training + 266 Testing)  \n",
        "Source: BRATS 2016 and 2017 datasets.  \n",
        "Challenge: **Drop some of the modalities randomly and reconstruct it by imputing with a 3D U-Net**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0snKkoyKX7M"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwSQBSa6KX7N",
        "outputId": "873f7ea4-f247-448e-83c1-a60ea4652737",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n",
        "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
        "# !python -c \"import onnxruntime\" || pip install -q onnxruntime\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDR2QhuhKX7O"
      },
      "source": [
        "## Setup imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uzoUh4uKX7P",
        "outputId": "8bb638f6-dd68-4ffd-84c2-2d30953b9190",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import tempfile\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from monai.apps import DecathlonDataset\n",
        "from monai.config import print_config\n",
        "from monai.data import DataLoader, decollate_batch\n",
        "from monai.handlers.utils import from_engine\n",
        "from monai.losses import DiceLoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.networks.nets import SegResNet\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    Activationsd,\n",
        "    AsDiscrete,\n",
        "    AsDiscreted,\n",
        "    Compose,\n",
        "    Invertd,\n",
        "    LoadImaged,\n",
        "    MapTransform,\n",
        "    NormalizeIntensityd,\n",
        "    Orientationd,\n",
        "    RandFlipd,\n",
        "    RandScaleIntensityd,\n",
        "    RandShiftIntensityd,\n",
        "    RandSpatialCropd,\n",
        "    Spacingd,\n",
        "    EnsureTyped,\n",
        "    EnsureChannelFirstd,\n",
        ")\n",
        "from monai.utils import set_determinism\n",
        "# import onnxruntime\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "\n",
        "print_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk54h-hVKX7P"
      },
      "source": [
        "## Setup data directory\n",
        "\n",
        "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
        "This allows you to save results and reuse downloads.  \n",
        "If not specified a temporary directory will be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqptOzFZT5xL",
        "outputId": "88acd11f-d256-430d-eaea-4ca1a9d3c93c"
      },
      "outputs": [],
      "source": [
        "os.environ[\"MONAI_DATA_DIRECTORY\"] = \"/scratch1/sachinsa/monai_data_1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c01pTrquKX7Q",
        "outputId": "e9781d95-fd2e-412b-9e3e-8269aa8633e4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
        "if directory is not None:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
        "print(root_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXLaSctjKX7Q"
      },
      "source": [
        "## Set deterministic training for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeNCIs06KX7R"
      },
      "outputs": [],
      "source": [
        "set_determinism(seed=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIdkcy6HqyLt",
        "outputId": "4503fa60-6d42-4cb8-ceea-5740fab451dc"
      },
      "outputs": [],
      "source": [
        "train_ds_1 = DecathlonDataset(\n",
        "    root_dir=root_dir,\n",
        "    task=\"Task01_BrainTumour\",\n",
        "    # transform=train_transform,\n",
        "    section=\"training\",\n",
        "    download=True,\n",
        "    cache_rate=0.0,\n",
        "    num_workers=4,\n",
        ")\n",
        "\n",
        "train_ds_2 = DecathlonDataset(\n",
        "    root_dir=root_dir,\n",
        "    task=\"Task01_BrainTumour\",\n",
        "    # transform=train_transform,\n",
        "    section=\"training\",\n",
        "    download=True,\n",
        "    cache_rate=0.0,\n",
        "    num_workers=4,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flNrdh3i4B9n",
        "outputId": "10229ac1-6f15-49aa-98df-53eae3fa5ff2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_boolean_list():\n",
        "    while True:\n",
        "        # np.random.seed(42)\n",
        "        # Generate a boolean array where each entry is True with 20% probability\n",
        "        bool_array = np.random.rand(4) < 0.2\n",
        "\n",
        "        # Check if at least one value is False\n",
        "        if not np.all(bool_array):\n",
        "            return np.where(bool_array)[0].tolist()\n",
        "\n",
        "true_indices = generate_boolean_list()\n",
        "print(\"Indices where True:\", true_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Challenge (unsolved): How to ensure only input images have some modalities dropped, and output modalities have the entire data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "WZBUwi8UsHhu",
        "outputId": "b627d7c0-6e12-4bc3-dbc6-5b1096142683"
      },
      "outputs": [],
      "source": [
        "from monai.transforms import (\n",
        "    RandCoarseDropoutD,\n",
        ")\n",
        "\n",
        "class RandomDropd(MapTransform):\n",
        "    def __call__(self, data):\n",
        "        d = dict(data)\n",
        "        for key in self.keys:\n",
        "            result = []\n",
        "            drop_indices = generate_boolean_list()\n",
        "            if len(drop_indices):\n",
        "              d[key][drop_indices] = 0\n",
        "        return d\n",
        "\n",
        "# SACHIN NOTE: Only \"image\", \"label\" are supported keys\n",
        "train_ds_1.transform = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\"]),\n",
        "        EnsureTyped(keys=[\"image\"]),\n",
        "        RandomDropd(keys=[\"image\"]), #, prob=0.1),\n",
        "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
        "        # Spacingd(\n",
        "        #     keys=[\"image\"],\n",
        "        #     pixdim=(1.0, 1.0, 1.0),\n",
        "        #     mode=(\"bilinear\", \"nearest\"),\n",
        "        # ),\n",
        "        # RandCoarseDropoutD(keys=[\"image\"], holes = 2, spatial_size = (96, 96, 96), fill_value = 0, prob=1.0),\n",
        "        RandSpatialCropd(keys=[\"image\"], roi_size=[224, 224, 144], random_size=False),\n",
        "        RandFlipd(keys=[\"image\"], prob=0.5, spatial_axis=0),\n",
        "        RandFlipd(keys=[\"image\"], prob=0.5, spatial_axis=1),\n",
        "        RandFlipd(keys=[\"image\"], prob=0.5, spatial_axis=2),\n",
        "        NormalizeIntensityd(keys=[\"image\"], nonzero=True, channel_wise=True),\n",
        "        RandScaleIntensityd(keys=[\"image\"], factors=0.1, prob=1.0),\n",
        "        RandShiftIntensityd(keys=[\"image\"], offsets=0.1, prob=1.0),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_data_example = train_ds_1[2]['image']\n",
        "print(f\"image shape: {val_data_example.shape}\")\n",
        "plt.figure(\"image\", (24, 6))\n",
        "for i in range(4):\n",
        "    plt.subplot(1, 4, i + 1)\n",
        "    plt.title(f\"image channel {i}\")\n",
        "    plt.imshow(val_data_example[i, :, :, 60].detach().cpu(), cmap=\"gray\")\n",
        "    plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "######################################\n",
        "\n",
        "class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n",
        "    \"\"\"\n",
        "    Convert labels to multi channels based on brats classes:\n",
        "    label 1 is the peritumoral edema\n",
        "    label 2 is the GD-enhancing tumor\n",
        "    label 3 is the necrotic and non-enhancing tumor core\n",
        "    The possible classes are TC (Tumor core), WT (Whole tumor)\n",
        "    and ET (Enhancing tumor).\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, data):\n",
        "        d = dict(data)\n",
        "        for key in self.keys:\n",
        "            result = []\n",
        "            # merge label 2 and label 3 to construct TC\n",
        "            result.append(torch.logical_or(d[key] == 2, d[key] == 3))\n",
        "            # merge labels 1, 2 and 3 to construct WT\n",
        "            result.append(torch.logical_or(torch.logical_or(d[key] == 2, d[key] == 3), d[key] == 1))\n",
        "            # label 2 is ET\n",
        "            result.append(d[key] == 2)\n",
        "            d[key] = torch.stack(result, axis=0).float()\n",
        "        return d\n",
        "    \n",
        "train_ds_2.transform = Compose(\n",
        "    [\n",
        "        # load 4 Nifti images and stack them together\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=\"image\"),\n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "        Spacingd(\n",
        "            keys=[\"image\", \"label\"],\n",
        "            pixdim=(1.0, 1.0, 1.0),\n",
        "            mode=(\"bilinear\", \"nearest\"),\n",
        "        ),\n",
        "        RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=[224, 224, 144], random_size=False),\n",
        "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
        "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
        "        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
        "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
        "        RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
        "        RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_data_example = train_ds_2[2]['image']\n",
        "print(f\"image shape: {val_data_example.shape}\")\n",
        "plt.figure(\"image\", (24, 6))\n",
        "for i in range(4):\n",
        "    plt.subplot(1, 4, i + 1)\n",
        "    plt.title(f\"image channel {i}\")\n",
        "    plt.imshow(val_data_example[i, :, :, 60].detach().cpu(), cmap=\"gray\")\n",
        "    plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yob6T4xKX7S"
      },
      "source": [
        "## Setup transforms for training and validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1zn16zLKX7S"
      },
      "outputs": [],
      "source": [
        "train_transform = Compose(\n",
        "    [\n",
        "        # load 4 Nifti images and stack them together\n",
        "        LoadImaged(keys=[\"image\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\"]),\n",
        "        EnsureTyped(keys=[\"image\"]),\n",
        "        # RandomDropd(keys=[\"in_image\"], prob=0.1), # TODO\n",
        "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
        "        # Spacingd(\n",
        "        #     keys=[\"image\"],\n",
        "        #     pixdim=(1.0, 1.0, 1.0),\n",
        "        #     mode=(\"bilinear\", \"nearest\"),\n",
        "        # ),\n",
        "        RandSpatialCropd(keys=[\"image\"], roi_size=[224, 224, 144], random_size=False),\n",
        "        RandFlipd(keys=[\"image\"], prob=0.5, spatial_axis=0),\n",
        "        RandFlipd(keys=[\"image\"], prob=0.5, spatial_axis=1),\n",
        "        RandFlipd(keys=[\"image\"], prob=0.5, spatial_axis=2),\n",
        "        NormalizeIntensityd(keys=[\"image\"], nonzero=True, channel_wise=True),\n",
        "        RandScaleIntensityd(keys=[\"image\"], factors=0.1, prob=1.0),\n",
        "        RandShiftIntensityd(keys=[\"image\"], offsets=0.1, prob=1.0),\n",
        "    ]\n",
        ")\n",
        "val_transform = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\"]),\n",
        "        EnsureTyped(keys=[\"image\"]),\n",
        "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
        "        # Spacingd(\n",
        "        #     keys=[\"image\"],\n",
        "        #     pixdim=(1.0, 1.0, 1.0),\n",
        "        #     mode=(\"bilinear\", \"nearest\"),\n",
        "        # ),\n",
        "        NormalizeIntensityd(keys=[\"image\"], nonzero=True, channel_wise=True),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G5INCNFKX7S"
      },
      "source": [
        "## Quickly load data with DecathlonDataset\n",
        "\n",
        "Here we use `DecathlonDataset` to automatically download and extract the dataset.\n",
        "It inherits MONAI `CacheDataset`, if you want to use less memory, you can set `cache_num=N` to cache N items for training and use the default args to cache all the items for validation, it depends on your memory size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF6T7PFsKX7S",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# here we don't cache any data in case out of memory issue\n",
        "train_ds = DecathlonDataset(\n",
        "    root_dir=root_dir,\n",
        "    task=\"Task01_BrainTumour\",\n",
        "    transform=train_transform,\n",
        "    section=\"training\",\n",
        "    download=True,\n",
        "    cache_rate=0.0,\n",
        "    num_workers=4,\n",
        ")\n",
        "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=4)\n",
        "val_ds = DecathlonDataset(\n",
        "    root_dir=root_dir,\n",
        "    task=\"Task01_BrainTumour\",\n",
        "    transform=val_transform,\n",
        "    section=\"validation\",\n",
        "    download=False,\n",
        "    cache_rate=0.0,\n",
        "    num_workers=4,\n",
        ")\n",
        "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dhVJ9qbVbGR"
      },
      "source": [
        "Consider a subset of train and validation dataset for debugging the training workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRkpcvfEHY7Q"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "train_subs = Subset(train_ds, list(range(30)))\n",
        "val_subs = Subset(val_ds, list(range(20)))\n",
        "\n",
        "train_loader = DataLoader(train_subs, batch_size=1, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_subs, batch_size=1, shuffle=False, num_workers=2)\n",
        "print(len(train_loader), len(val_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXd4zV8DKX7S"
      },
      "source": [
        "## Check data shape and visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnvWc-L1KX7S"
      },
      "outputs": [],
      "source": [
        "# pick one image from DecathlonDataset to visualize and check the 4 channels\n",
        "val_data_example = val_ds[2]\n",
        "print(f\"image shape: {val_data_example['image'].shape}\")\n",
        "plt.figure(\"image\", (24, 6))\n",
        "for i in range(4):\n",
        "    plt.subplot(1, 4, i + 1)\n",
        "    plt.title(f\"image channel {i}\")\n",
        "    plt.imshow(val_data_example[\"image\"][i, :, :, 60].detach().cpu(), cmap=\"gray\")\n",
        "    plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3e3iR-hKX7T"
      },
      "source": [
        "## Create Model, Loss, Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WScmgodkdmwU"
      },
      "source": [
        "**Define a 3D Unet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeDy37CJdqCT"
      },
      "outputs": [],
      "source": [
        "from monai.networks.nets import UNet\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "model = UNet(\n",
        "    spatial_dims=3, # 3D\n",
        "    in_channels=4,\n",
        "    out_channels=8, # we will output estimated mean and estimated std dev for all 4 image channels\n",
        "    channels=(4, 8, 16),\n",
        "    strides=(2, 2),\n",
        "    num_res_units=2\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmxkPH4GKX7T"
      },
      "outputs": [],
      "source": [
        "def GaussianLikelihood(expected_img, output_img):\n",
        "    # input is 4 channel images, output is 8 channel images\n",
        "    # TODO (DONE): Deal sigma<=0 issue by either initializing to 1 or adding a small constant\n",
        "    #   Dealt it using sigma\n",
        "\n",
        "    output_img_mean = output_img[:, :4, ...]\n",
        "    output_img_log_std = output_img[:, 4:, ...]\n",
        "    cost1 = (expected_img - output_img_mean)**2 / (2*torch.exp(2*output_img_log_std))\n",
        "\n",
        "    cost2 = output_img_log_std\n",
        "\n",
        "    return torch.mean(cost1 + cost2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "from monai.metrics import MSEMetric\n",
        "\n",
        "max_epochs = 20 # 300\n",
        "val_interval = 4\n",
        "VAL_AMP = True\n",
        "\n",
        "# Define the loss function\n",
        "loss_function = GaussianLikelihood #nn.MSELoss()\n",
        "# loss_function = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True, to_onehot_y=False, sigmoid=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
        "\n",
        "# mse_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
        "# mse_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
        "\n",
        "mse_metric = MSEMetric(reduction=\"mean\")\n",
        "mse_metric_batch = MSEMetric(reduction=\"mean_batch\")\n",
        "\n",
        "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
        "\n",
        "\n",
        "# define inference method\n",
        "def inference(input):\n",
        "    def _compute(input):\n",
        "        output = model(input)\n",
        "        return output\n",
        "\n",
        "    if VAL_AMP:\n",
        "        with torch.cuda.amp.autocast():\n",
        "            return _compute(input)\n",
        "    else:\n",
        "        return _compute(input)\n",
        "\n",
        "\n",
        "# use amp to accelerate training\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "# enable cuDNN benchmark\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pdb; "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8xDYlbRKX7T",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "best_metrics_epochs_and_time = [[], [], []]\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "metric_values_tc = []\n",
        "metric_values_wt = []\n",
        "metric_values_et = []\n",
        "\n",
        "total_start = time.time()\n",
        "for epoch in range(max_epochs):\n",
        "    epoch_start = time.time()\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in train_loader:\n",
        "        step_start = time.time()\n",
        "        step += 1\n",
        "        inputs, outputs_gt = (\n",
        "            batch_data[\"image\"].to(device),\n",
        "            batch_data[\"image\"].to(device),\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            mask_indices = [0, 2] # generate_boolean_list()\n",
        "            inputs[:, mask_indices, ...] = 0\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs_gt, outputs)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        epoch_loss += loss.item()\n",
        "        print(\n",
        "            f\"{step}/{len(train_subs) // train_loader.batch_size}\"\n",
        "            f\", train_loss: {loss.item():.4f}\"\n",
        "            f\", step time: {(time.time() - step_start):.4f}\"\n",
        "        )\n",
        "    lr_scheduler.step()\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for val_data in val_loader:\n",
        "                val_inputs, val_outputs_gt = (\n",
        "                    batch_data[\"image\"].to(device),\n",
        "                    batch_data[\"image\"].to(device),\n",
        "                )\n",
        "                val_outputs = inference(val_inputs)\n",
        "                val_outputs = val_outputs[:, :4, ...]\n",
        "                # val_outputs = [post_trans(i) for i in val_outputs]\n",
        "                mse_metric(y_pred=val_outputs, y=val_outputs_gt)\n",
        "                mse_metric_batch(y_pred=val_outputs, y=val_outputs_gt)\n",
        "\n",
        "            metric = mse_metric.aggregate().item()\n",
        "            metric_values.append(metric)\n",
        "            metric_batch = mse_metric_batch.aggregate()\n",
        "            mse_metric.reset()\n",
        "            mse_metric_batch.reset()\n",
        "\n",
        "            if metric > best_metric:\n",
        "                best_metric = metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                best_metrics_epochs_and_time[0].append(best_metric)\n",
        "                best_metrics_epochs_and_time[1].append(best_metric_epoch)\n",
        "                best_metrics_epochs_and_time[2].append(time.time() - total_start)\n",
        "                torch.save(\n",
        "                    model.state_dict(),\n",
        "                    os.path.join(root_dir, \"best_metric_model.pth\"),\n",
        "                )\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current mean mse: {metric:.4f}\"\n",
        "                f\"\\nbest mean metric: {best_metric:.4f}\"\n",
        "                f\" at epoch: {best_metric_epoch}\"\n",
        "            )\n",
        "    print(f\"time consuming of epoch {epoch + 1} is: {(time.time() - epoch_start):.4f}\")\n",
        "total_time = time.time() - total_start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnK_38mOKX7T",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}, total time: {total_time}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riunGatZKX7U"
      },
      "source": [
        "## Plot the loss and metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "857pko9yKX7U"
      },
      "outputs": [],
      "source": [
        "plt.figure(\"train\", (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Epoch Average Loss\")\n",
        "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
        "y = epoch_loss_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y, color=\"red\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Val Mean MSE\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
        "y = metric_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y, color=\"green\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5KqMhb9KX7U"
      },
      "source": [
        "## Check best pytorch model output with the input image and label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6qGjJlIKX7U"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # select one image to evaluate and visualize the model output\n",
        "    val_input = val_ds[6][\"image\"].unsqueeze(0).to(device)\n",
        "    mask_indices = [0, 2] # generate_boolean_list()\n",
        "    val_input[:, mask_indices, ...] = 0\n",
        "    val_output = inference(val_input)\n",
        "    # val_output = post_trans(val_output[0])\n",
        "    plt.figure(\"image\", (24, 6))\n",
        "    for i in range(4):\n",
        "        plt.subplot(1, 4, i + 1)\n",
        "        plt.title(f\"image channel {i}\")\n",
        "        plt.imshow(val_input[0, i, :, :, 70].detach().cpu(), cmap=\"gray\")\n",
        "    plt.show()\n",
        "    # visualize the 3 channels model output corresponding to this image\n",
        "    plt.figure(\"output mean\", (24, 6))\n",
        "    for i in range(4):\n",
        "        plt.subplot(1, 4, i + 1)\n",
        "        plt.title(f\"output channel {i}\")\n",
        "        plt.imshow(val_output[0, i, :, :, 70].detach().cpu(), cmap=\"gray\")\n",
        "\n",
        "    plt.figure(\"output std\", (24, 6))\n",
        "    for i in range(4):\n",
        "        plt.subplot(1, 4, i + 1)\n",
        "        plt.title(f\"output channel {i}\")\n",
        "        plt.imshow(val_output[0, i+4, :, :, 70].detach().cpu(), cmap=\"gray\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt9PmngFKX7V"
      },
      "source": [
        "## Cleanup data directory\n",
        "\n",
        "Remove directory if a temporary was used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcK1sIkiKX7W"
      },
      "outputs": [],
      "source": [
        "if directory is None:\n",
        "    shutil.rmtree(root_dir)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv-4",
      "language": "python",
      "name": "myenv-4"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
