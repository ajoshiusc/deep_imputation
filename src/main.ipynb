{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLtiAWdGKX7J"
      },
      "source": [
        "# Deep Imputation of BraTS dataset with MONAI\n",
        "\n",
        "The dataset comes from http://medicaldecathlon.com/.  \n",
        "Modality: Multimodal multisite MRI data (FLAIR, T1w, T1gd,T2w)  \n",
        "Size: 750 4D volumes (484 Training + 266 Testing)  \n",
        "Source: BRATS 2016 and 2017 datasets.  \n",
        "Challenge: **Drop some of the modalities randomly and reconstruct it by imputing with a 3D U-Net**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from logger import Logger\n",
        "logger = Logger(log_level='DEBUG')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set parameters\n",
        "\n",
        "* run_id : set this to prevent overlapped saving of model and data\n",
        "\n",
        "* DO_MASK : Set to True if mask is to be applied while training\n",
        "* SET_VARIANCE : Set to True if variance is to be trained in loss function\n",
        "* PIXEL_DOWNSAMPLE : How much to scale down each axis. In other words, mm per pixel/voxel\n",
        "\n",
        "* max_epochs\n",
        "* val_interval : how frequently the validation code should be run\n",
        "* TRAIN_RATIO: proportion of total dataset to be used for training. Rest will be used for validating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_id = 2\n",
        "DO_MASK = False\n",
        "SET_VARIANCE = False\n",
        "PIXEL_DOWNSAMPLE = [2, 2, 2]\n",
        "max_epochs = 100\n",
        "val_interval = 10\n",
        "TRAIN_RATIO = 0.8\n",
        "TRAIN_DATA_SIZE = 100\n",
        "RANDOM_SEED = 0\n",
        "root_dir = \"/scratch1/sachinsa/monai_data_1\"\n",
        "\n",
        "logger.info(\"PARAMETERS\\n-----------------\")\n",
        "logger.info(f\"run_id: {run_id}\")\n",
        "logger.info(f\"DO_MASK: {DO_MASK}\")\n",
        "logger.info(f\"SET_VARIANCE: {SET_VARIANCE}\")\n",
        "logger.info(f\"PIXEL_DOWNSAMPLE: {PIXEL_DOWNSAMPLE}\")\n",
        "logger.info(f\"max_epochs: {max_epochs}\")\n",
        "logger.info(f\"val_interval: {val_interval}\")\n",
        "logger.info(f\"TRAIN_RATIO: {TRAIN_RATIO}\")\n",
        "logger.info(f\"RANDOM_SEED: {RANDOM_SEED}\")\n",
        "logger.info(f\"Root dir: {root_dir}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check if this is a notebook or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def is_notebook():\n",
        "    try:\n",
        "        shell = get_ipython().__class__.__name__\n",
        "        if shell == 'ZMQInteractiveShell':\n",
        "            return True  # Jupyter notebook or Jupyter QtConsole\n",
        "        elif shell == 'TerminalInteractiveShell':\n",
        "            return False  # Terminal running IPython\n",
        "        else:\n",
        "            return False  # Other types\n",
        "    except NameError:\n",
        "        return False  # Standard Python interpreter\n",
        "\n",
        "# Example usage\n",
        "if is_notebook():\n",
        "    logger.debug(\"This is a Jupyter Notebook.\")\n",
        "else:\n",
        "    logger.debug(\"This is a Python script (not a Jupyter Notebook).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0snKkoyKX7M"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwSQBSa6KX7N",
        "outputId": "873f7ea4-f247-448e-83c1-a60ea4652737",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# if is_notebook():\n",
        "#     get_ipython().system('python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"')\n",
        "#     get_ipython().system('python -c \"import matplotlib\" || pip install -q matplotlib')\n",
        "#     get_ipython().run_line_magic('matplotlib', 'inline')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDR2QhuhKX7O"
      },
      "source": [
        "## Setup imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uzoUh4uKX7P",
        "outputId": "8bb638f6-dd68-4ffd-84c2-2d30953b9190",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import tempfile\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from monai.config import print_config\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    AsDiscrete,\n",
        "    Compose,\n",
        ")\n",
        "from monai.networks.nets import UNet\n",
        "from monai.transforms import (\n",
        "    LoadImage,\n",
        "    Resize,\n",
        "    NormalizeIntensity,\n",
        "    Orientation,\n",
        "    RandFlip,\n",
        "    RandScaleIntensity,\n",
        "    RandShiftIntensity,\n",
        "    RandSpatialCrop,\n",
        "    CenterSpatialCrop,\n",
        "    Spacing,\n",
        "    EnsureType,\n",
        "    EnsureChannelFirst,\n",
        ")\n",
        "from monai.metrics import MSEMetric\n",
        "from monai.utils import set_determinism\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pdb\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "print_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk54h-hVKX7P"
      },
      "source": [
        "## Setup data directory\n",
        "\n",
        "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
        "This allows you to save results and reuse downloads.  \n",
        "If not specified a temporary directory will be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqptOzFZT5xL",
        "outputId": "88acd11f-d256-430d-eaea-4ca1a9d3c93c"
      },
      "outputs": [],
      "source": [
        "os.environ[\"MONAI_DATA_DIRECTORY\"] = root_dir\n",
        "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
        "if directory is not None:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
        "logger.debug(f\"Root dir: {root_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_dir = os.path.join(root_dir, f\"run_{run_id}\")\n",
        "if os.path.exists(save_dir) and os.path.isdir(save_dir) and len(os.listdir(save_dir)) != 0:\n",
        "    logger.warning(f\"{save_dir} already exists. Avoid overwrite by updating run_id.\")\n",
        "    exit()\n",
        "else:\n",
        "    os.makedirs(save_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXLaSctjKX7Q"
      },
      "source": [
        "### Set deterministic training for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeNCIs06KX7R"
      },
      "outputs": [],
      "source": [
        "set_determinism(seed=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yob6T4xKX7S"
      },
      "source": [
        "## Setup transforms for training and validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1zn16zLKX7S"
      },
      "outputs": [],
      "source": [
        "crop_size = [224, 224, 144]\n",
        "resize_size = [crop_size[i]//PIXEL_DOWNSAMPLE[i] for i in range(len(crop_size))]\n",
        "\n",
        "train_transform = Compose(\n",
        "    [\n",
        "        # load 4 Nifti images and stack them together\n",
        "        LoadImage(),\n",
        "        EnsureChannelFirst(),\n",
        "        EnsureType(),\n",
        "        Orientation(axcodes=\"RAS\"),\n",
        "        Spacing(\n",
        "            pixdim=(1.0, 1.0, 1.0),\n",
        "            mode=(\"bilinear\", \"nearest\"),\n",
        "        ),\n",
        "        RandSpatialCrop(roi_size=crop_size, random_size=False),\n",
        "        Resize(spatial_size=resize_size, mode='nearest'),\n",
        "        RandFlip(prob=0.5, spatial_axis=0),\n",
        "        RandFlip(prob=0.5, spatial_axis=1),\n",
        "        RandFlip(prob=0.5, spatial_axis=2),\n",
        "        NormalizeIntensity(nonzero=True, channel_wise=True),\n",
        "        RandScaleIntensity(factors=0.1, prob=1.0),\n",
        "        RandShiftIntensity(offsets=0.1, prob=1.0),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_transform = Compose(\n",
        "    [\n",
        "        LoadImage(),\n",
        "        EnsureChannelFirst(),\n",
        "        EnsureType(),\n",
        "        Orientation(axcodes=\"RAS\"),\n",
        "        Spacing(\n",
        "            pixdim=(1.0, 1.0, 1.0),\n",
        "            mode=(\"bilinear\", \"nearest\"),\n",
        "        ),\n",
        "        CenterSpatialCrop(roi_size=crop_size), # added this because model was not handling 155dims\n",
        "        Resize(spatial_size=resize_size, mode='nearest'),\n",
        "        NormalizeIntensity(nonzero=True, channel_wise=True),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Dataset to load MRI and mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def int_to_bool_binary(int_list, length):\n",
        "    # Convert each integer to its base-2 value and represent it as boolean, always ensuring length is 4\n",
        "    bool_list = []\n",
        "    \n",
        "    for num in int_list:\n",
        "        # Get the binary representation of the integer (excluding the '0b' prefix)\n",
        "        binary_str = bin(num)[2:]\n",
        "        # Convert each character in the binary string to a boolean\n",
        "        bools = [char == '1' for char in binary_str]\n",
        "        # Prepend False (0s) to make the length exactly 4\n",
        "        bools_padded = [False] * (length - len(bools)) + bools\n",
        "        bool_list.append(bools_padded)\n",
        "    \n",
        "    return np.array(bool_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BrainMRIDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = os.path.join(root_dir, \"Task01_BrainTumour\")\n",
        "        json_file_path = os.path.join(self.root_dir, \"dataset.json\")\n",
        "        with open(json_file_path, 'r') as file:\n",
        "            data_json = json.load(file)\n",
        "\n",
        "        self.image_filenames = data_json['training']\n",
        "\n",
        "        np.random.seed(RANDOM_SEED)\n",
        "        num_seq = 4\n",
        "        if DO_MASK:\n",
        "            mask_drop_code = np.random.randint(0, 2**(num_seq) - 1, size=len(self.image_filenames))\n",
        "            self.seq_mask = int_to_bool_binary(mask_drop_code, length=num_seq)\n",
        "        else:\n",
        "            self.seq_mask = np.full((len(self.image_filenames), num_seq), False, dtype=bool)\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.normpath(os.path.join(self.root_dir,self.image_filenames[idx]['image']))\n",
        "        mask = self.seq_mask[idx]\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(img_name)\n",
        "\n",
        "        mask = torch.from_numpy(mask)\n",
        "\n",
        "        return {\"image\":image, \"mask\":mask}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dhVJ9qbVbGR"
      },
      "source": [
        "Create training and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRkpcvfEHY7Q"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "\n",
        "all_dataset = BrainMRIDataset(\n",
        "    root_dir=root_dir\n",
        ")\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset, val_dataset = random_split(all_dataset, [TRAIN_RATIO, 1-TRAIN_RATIO],\n",
        "                                          generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
        "\n",
        "train_dataset.dataset.transform = train_transform\n",
        "val_dataset.dataset.transform = val_transform\n",
        "\n",
        "if TRAIN_DATA_SIZE:\n",
        "    train_dataset = Subset(train_dataset, list(range(TRAIN_DATA_SIZE)))\n",
        "    val_dataset = Subset(train_dataset, list(range(TRAIN_DATA_SIZE//4)))\n",
        "\n",
        "logger.debug(\"Data loading...\")\n",
        "\n",
        "# Create data loaders\n",
        "BATCHSIZE_TRAIN, BATCHSIZE_VAL = 2, 2\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCHSIZE_TRAIN, shuffle=True,\n",
        "    num_workers=8)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCHSIZE_VAL, shuffle=False, num_workers=8)\n",
        "\n",
        "logger.debug(\"Data loaded\")\n",
        "logger.debug(f\"Length of dataset: {len(train_dataset)}, {len(val_dataset)}\")\n",
        "logger.debug(f\"Batch-size: {BATCHSIZE_TRAIN}, {BATCHSIZE_VAL}\")\n",
        "logger.debug(f\"Length of data-loaders: {len(train_loader)}, {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXd4zV8DKX7S"
      },
      "source": [
        "## Check data shape and visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnvWc-L1KX7S"
      },
      "outputs": [],
      "source": [
        "# pick one image from DecathlonDataset to visualize and check the 4 channels\n",
        "if is_notebook():\n",
        "    channels = [\"FLAIR\", \"T1w\", \"T1gd\", \"T2w\"]\n",
        "    val_data_example = val_dataset[0]['image']\n",
        "    _, im_length, im_width, im_height = val_data_example.shape\n",
        "    logger.debug(f\"image shape: {val_data_example.shape}\")\n",
        "    plt.figure(\"image\", (24, 6))\n",
        "    for i in range(4):\n",
        "        plt.subplot(1, 4, i + 1)\n",
        "        plt.title(channels[i], fontsize=30)\n",
        "        brain_slice = val_data_example[i, :, :, im_height//2].detach().cpu().T\n",
        "        plt.xticks([0, im_width - 1], [0, im_width - 1], fontsize=15)\n",
        "        plt.yticks([0, im_length - 1], [0, im_length - 1], fontsize=15)\n",
        "        plt.imshow(brain_slice, cmap=\"gray\")\n",
        "        cbar = plt.colorbar()\n",
        "        cbar.ax.tick_params(labelsize=20)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3e3iR-hKX7T"
      },
      "source": [
        "## Create Model, Loss, Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WScmgodkdmwU"
      },
      "source": [
        "**Define a 3D Unet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeDy37CJdqCT"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "model = UNet(\n",
        "    spatial_dims=3, # 3D\n",
        "    in_channels=4,\n",
        "    out_channels=8, # we will output estimated mean and estimated std dev for all 4 image channels\n",
        "    channels=(4, 8, 16),\n",
        "    strides=(2, 2),\n",
        "    num_res_units=2\n",
        ").to(device)\n",
        "logger.debug(\"Model defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate and display the total number of parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "total_params = count_parameters(model)\n",
        "logger.debug(f\"Total number of trainable parameters: {total_params}\")\n",
        "\n",
        "# Print the model architecture\n",
        "logger.debug(f\"Model Architecture:\\n {model}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Loss (Guassian Likelihood)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def GaussianLikelihood(expected_img, output_img):\n",
        "    # input is 4 channel images, output is 8 channel images\n",
        "\n",
        "    output_img_mean = output_img[:, :4, ...]\n",
        "    if SET_VARIANCE:\n",
        "        output_img_log_std = output_img[:, 4:, ...]\n",
        "    else:\n",
        "        output_img_log_std = torch.zeros_like(output_img[:, 4:, ...]) # sigma = 1\n",
        "\n",
        "    cost1 = (expected_img - output_img_mean)**2 / (2*torch.exp(2*output_img_log_std))\n",
        "    cost2 = output_img_log_std\n",
        "\n",
        "    return torch.mean(cost1 + cost2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmxkPH4GKX7T"
      },
      "outputs": [],
      "source": [
        "VAL_AMP = True\n",
        "\n",
        "# Define the loss function\n",
        "loss_function = GaussianLikelihood #nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
        "\n",
        "mse_metric = MSEMetric(reduction=\"mean\")\n",
        "mse_metric_batch = MSEMetric(reduction=\"mean_batch\")\n",
        "\n",
        "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
        "\n",
        "\n",
        "# define inference method\n",
        "def inference(input):\n",
        "    def _compute(input):\n",
        "        output = model(input)\n",
        "        return output\n",
        "\n",
        "    if VAL_AMP:\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            return _compute(input)\n",
        "    else:\n",
        "        return _compute(input)\n",
        "\n",
        "\n",
        "# use amp to accelerate training\n",
        "scaler = torch.amp.GradScaler('cuda')\n",
        "# enable cuDNN benchmark\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8xDYlbRKX7T",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "best_metrics_epochs_and_time = [[], [], []]\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "metric_values_tc = []\n",
        "metric_values_wt = []\n",
        "metric_values_et = []\n",
        "\n",
        "logger.debug(\"Beginning training...\")\n",
        "total_start = time.time()\n",
        "for epoch in range(max_epochs):\n",
        "    epoch_start = time.time()\n",
        "    logger.info(\"-\" * 10)\n",
        "    logger.info(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    step_start = time.time()\n",
        "    for batch_data in train_loader:\n",
        "        data_loaded_time = time.time() - step_start\n",
        "        step += 1\n",
        "        inputs, mask = (\n",
        "            batch_data[\"image\"].to(device),\n",
        "            batch_data[\"mask\"].to(device),\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            outputs_gt = inputs.clone()\n",
        "            inputs = inputs*~mask[:,:,None,None,None]\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs_gt, outputs)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        epoch_loss += loss.item()\n",
        "        logger.info(\n",
        "            f\"{step}/{len(train_loader)}\"\n",
        "            f\", train_loss: {loss.item():.4f}\"\n",
        "            f\", data-load time: {(data_loaded_time):.4f}\"\n",
        "            f\", total-step time: {(time.time() - step_start):.4f}\"\n",
        "        )\n",
        "        step_start = time.time()\n",
        "    lr_scheduler.step()\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    logger.info(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for val_data in val_loader:\n",
        "                val_inputs, val_mask = (\n",
        "                    batch_data[\"image\"].to(device),\n",
        "                    batch_data[\"mask\"].to(device),\n",
        "                )\n",
        "                val_outputs_gt = val_inputs.clone()\n",
        "                val_inputs = val_inputs*~val_mask[:,:,None,None,None]\n",
        "                val_outputs = inference(val_inputs)\n",
        "                val_outputs = val_outputs[:,:4,...]\n",
        "                # val_outputs = [post_trans(i) for i in val_outputs]\n",
        "                mse_metric(y_pred=val_outputs, y=val_outputs_gt)\n",
        "                mse_metric_batch(y_pred=val_outputs, y=val_outputs_gt)\n",
        "\n",
        "            metric = 1-mse_metric.aggregate().item()\n",
        "            metric_values.append(metric)\n",
        "            metric_batch = mse_metric_batch.aggregate()\n",
        "            mse_metric.reset()\n",
        "            mse_metric_batch.reset()\n",
        "\n",
        "            if metric > best_metric:\n",
        "                best_metric = metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                best_metrics_epochs_and_time[0].append(best_metric)\n",
        "                best_metrics_epochs_and_time[1].append(best_metric_epoch)\n",
        "                best_metrics_epochs_and_time[2].append(time.time() - total_start)\n",
        "                torch.save(\n",
        "                    model.state_dict(),\n",
        "                    os.path.join(save_dir, \"best_metric_model.pth\"),\n",
        "                )\n",
        "                logger.info(\"saved new best metric model\")\n",
        "                \n",
        "            # Save the loss list\n",
        "            np.save(os.path.join(save_dir, 'epoch_loss_values.npy'), np.array(epoch_loss_values))\n",
        "            np.save(os.path.join(save_dir, 'metric_values.npy'), np.array(metric_values))\n",
        "            logger.info(\n",
        "                f\"current epoch: {epoch + 1} current mean mse: {metric:.4f}\"\n",
        "                f\"\\nbest mean metric: {best_metric:.4f}\"\n",
        "                f\" at epoch: {best_metric_epoch}\"\n",
        "            )\n",
        "    logger.info(f\"time consuming of epoch {epoch + 1} is: {(time.time() - epoch_start):.4f}\")\n",
        "total_time = time.time() - total_start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnK_38mOKX7T",
        "tags": []
      },
      "outputs": [],
      "source": [
        "logger.info(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}, total time: {total_time}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the loss list\n",
        "np.save(os.path.join(save_dir, 'epoch_loss_values.npy'), np.array(epoch_loss_values))\n",
        "np.save(os.path.join(save_dir, 'metric_values.npy'), np.array(metric_values))\n",
        "del epoch_loss_values, metric_values\n",
        "logger.debug(\"training loss info saved\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv-4",
      "language": "python",
      "name": "myenv-4"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
