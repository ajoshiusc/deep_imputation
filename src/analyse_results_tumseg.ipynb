{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To analyse the brain segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = 40\n",
    "T1GD_SYNTH = True\n",
    "MASK_CODE = 0 #RUN_ID - 80\n",
    "if T1GD_SYNTH: MASK_CODE = 0\n",
    "RANDOM_SEED = 0\n",
    "ROOT_DIR = \"/scratch1/sachinsa/brats_seg\"\n",
    "DATA_ROOT_DIR = \"/scratch1/sachinsa/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pdb\n",
    "import numpy as np\n",
    "import pickle\n",
    "from utils.logger import Logger\n",
    "from utils.plot import *\n",
    "from itertools import chain, combinations\n",
    "\n",
    "logger = Logger(log_level='DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = os.path.join(ROOT_DIR, f\"run_{RUN_ID:03d}\")\n",
    "fig_save_dir = os.path.join(\"..\", \"figs\", f\"run_{RUN_ID:03d}\")\n",
    "os.makedirs(fig_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(load_dir, 'training_info.pkl'), 'rb') as f:\n",
    "    training_info = pickle.load(f)\n",
    "    epoch_loss_values = training_info['epoch_loss_values']\n",
    "    metric_values = training_info['metric_values']\n",
    "    metric_values_tc = training_info['metric_values_tc']\n",
    "    metric_values_wt = training_info['metric_values_wt']\n",
    "    metric_values_et = training_info['metric_values_et']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = len(epoch_loss_values)\n",
    "val_interval = len(epoch_loss_values)//len(metric_values)\n",
    "logger.info(f\"Total epochs: {max_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_subsets(arr):\n",
    "    subsets = list(chain.from_iterable(combinations(arr, r) for r in range(0, len(arr))))\n",
    "    return [list(subset) for subset in subsets]\n",
    "\n",
    "mask_indices = all_subsets([0, 1, 2, 3])[MASK_CODE]\n",
    "show_indices = [x for x in [0, 1, 2, 3] if x not in mask_indices]\n",
    "channels = [\"FLAIR\", \"T1w\", \"T1Gd\", \"T2w\"]\n",
    "label_list = [\"TC\", \"WT\", \"ET\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_tumor_seg(epoch_loss_values, metric_values, metric_values_tc, metric_values_wt, metric_values_et, val_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = np.max(metric_values)\n",
    "arg_max = np.argmax(metric_values)\n",
    "metric_tc = metric_values_tc[arg_max]\n",
    "metric_wt = metric_values_wt[arg_max]\n",
    "metric_et = metric_values_et[arg_max]\n",
    "\n",
    "print(f\"Masked contrasts: {[channels[i] for i in mask_indices]}\")\n",
    "print(f\"Epochs  Total\tTC\tWT\tET\")\n",
    "print(f\"{len(epoch_loss_values)}\t{100*metric:.1f}\t{100*metric_tc:.1f}\t{100*metric_wt:.1f}\t{100*metric_et:.1f}\")\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,4, figsize=(10, 3),gridspec_kw={'wspace': 0, 'hspace': 0})\n",
    "plot_donut(metric, \"Total\", \"green\", axs[0])\n",
    "plot_donut(metric_tc, \"TC\", \"blue\", axs[1])\n",
    "plot_donut(metric_wt, \"WT\", \"brown\", axs[2])\n",
    "plot_donut(metric_et, \"ET\", \"purple\", axs[3])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    ")\n",
    "from monai.config import print_config\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import SegResNet\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils.transforms import tumor_seg_transform as data_transform\n",
    "from utils.model import create_SegResNet, inference\n",
    "from utils.dataset import BraTSDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "in_channels = len(show_indices)\n",
    "model = create_SegResNet(in_channels, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
    "\n",
    "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = BraTSDataset(\n",
    "    version='2017',\n",
    "    # load_t1gd = T1GD_SYNTH,\n",
    "    processed = True,\n",
    "    section = 'all',\n",
    "    seed = RANDOM_SEED,\n",
    "    transform = data_transform['val']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(os.path.join(load_dir, 'best_checkpoint.pth'), weights_only=True)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ = 449 # np.sort(val_dataset.get_ids())[this_index]\n",
    "this_index += 1\n",
    "print(id_)\n",
    "\n",
    "with torch.no_grad():\n",
    "    this_input = val_dataset.get_with_id(id_)\n",
    "    input_image = this_input[\"image\"].unsqueeze(0).to(device)\n",
    "    if not T1GD_SYNTH:\n",
    "        input_image = input_image[:, show_indices, ...]\n",
    "    input_label = this_input[\"label\"]\n",
    "    this_output = inference(input_image, model)\n",
    "    this_output = post_trans(this_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ratio_of_ones(tensor):\n",
    "    total_elements = tensor.numel()\n",
    "    count_ones = torch.sum(tensor)\n",
    "    ratio = count_ones.float() / total_elements\n",
    "    return ratio.item()\n",
    "\n",
    "def tensor_to_sorted_tuple(tensor):\n",
    "    unique_values, counts = torch.unique(tensor, return_counts=True)\n",
    "    result = list(zip(unique_values.tolist(), counts.tolist()))\n",
    "    result.sort(key=lambda x: x[1], reverse=True)\n",
    "    return tuple(result)\n",
    "    \n",
    "def find_centroid_3d(tensor):\n",
    "    print(f\"TC: {find_ratio_of_ones(tensor)*100:.5f}%\")\n",
    "    indices = torch.nonzero(tensor, as_tuple=False)\n",
    "\n",
    "    print(len(indices))\n",
    "    print(tensor_to_sorted_tuple(indices[:, 2]))\n",
    "\n",
    "    if indices.shape[0] == 0:\n",
    "        shape = torch.tensor(tensor.shape, dtype=torch.float32)\n",
    "        midpoint = (shape - 1) / 2\n",
    "        return midpoint.round().to(torch.int64)\n",
    "\n",
    "    centroid = torch.mean(indices.float(), dim=0).round().to(torch.int64)\n",
    "    return centroid\n",
    "    \n",
    "label_centroid =  find_centroid_3d(input_label[0]) # centroid of TC (Tumor Core)\n",
    "print(label_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, im_length, im_width, im_height = input_image.shape\n",
    "h_index = label_centroid[-1]\n",
    "label_list = [\"TC\", \"WT\", \"ET\", \"Combined\"]\n",
    "channels = [\"FLAIR\", \"T1w\", \"T1gd\", \"T2w\"]\n",
    "\n",
    "def plot_brain(index, label):\n",
    "    if label == \"ground_truth\":\n",
    "        start_index = 1*len(channels)\n",
    "        brain_slice = input_label\n",
    "        title = \"Ground Truth\"\n",
    "    elif label == \"prediction\":\n",
    "        start_index = 2*len(channels)\n",
    "        brain_slice = this_output\n",
    "        title = \"Prediction\"\n",
    "\n",
    "    brain_slice = brain_slice[..., h_index].detach().cpu().T\n",
    "    if index < 3:\n",
    "        brain_slice = brain_slice[..., index]\n",
    "    else:\n",
    "        brain_slice = brain_slice.sum(axis=-1)\n",
    "    plt.subplot(3, 4, start_index + index + 1)\n",
    "    plt.title(label_list[index], fontsize=30)\n",
    "    if index == 0:\n",
    "        plt.ylabel(title, fontsize=30)\n",
    "    plt.xticks([0, im_width - 1], [0, im_width - 1], fontsize=15)\n",
    "    plt.yticks([0, im_length - 1], [0, im_length - 1], fontsize=15)\n",
    "    cmap = \"gray\" if index < 3 else \"magma\"\n",
    "    plt.imshow(brain_slice, cmap=cmap)\n",
    "\n",
    "\n",
    "plt.figure(\"image\", (24, 18))\n",
    "for i in range(len(show_indices)):\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    plt.title(channels[show_indices[i]], fontsize=30)\n",
    "    if i == 0:\n",
    "        plt.ylabel(\"Input\", fontsize=30)\n",
    "    plt.xticks([0, im_width - 1], [0, im_width - 1], fontsize=15)\n",
    "    plt.yticks([0, im_length - 1], [0, im_length - 1], fontsize=15)\n",
    "    brain_slice = input_image[0, i, :, :, h_index].detach().cpu().T\n",
    "    plt.imshow(brain_slice, cmap=\"gray\", vmin=-3, vmax=4)\n",
    "    plt.colorbar(shrink=0.7)\n",
    "# plt.suptitle(f\"BRATS_{this_input['id']} (h={h_index}/{im_height})\", fontsize=20)\n",
    "# plt.show()\n",
    "    \n",
    "# plt.figure(\"label\", (18, 12))\n",
    "for i in range(len(label_list)):\n",
    "    plot_brain(i, \"ground_truth\")\n",
    "for i in range(len(label_list)):\n",
    "    plot_brain(i, \"prediction\")\n",
    "plt.suptitle(f\"BRATS_{this_input['id']} (h={h_index}/{im_height})\", y=0.9, fontsize=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
