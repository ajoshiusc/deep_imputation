{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLtiAWdGKX7J"
   },
   "source": [
    "# Deep Imputation of BraTS dataset with MONAI\n",
    "\n",
    "The dataset comes from http://medicaldecathlon.com/.  \n",
    "Modality: Multimodal multisite MRI data (FLAIR, T1w, T1gd,T2w)  \n",
    "Size: 750 4D volumes (484 Training + 266 Testing)  \n",
    "Source: BRATS 2016 and 2017 datasets.  \n",
    "Challenge: **Drop some of the modalities randomly and reconstruct it by imputing with a 3D U-Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Logging level is: DEBUG\n"
     ]
    }
   ],
   "source": [
    "from logger import Logger\n",
    "logger = Logger(log_level='DEBUG')\n",
    "\n",
    "\n",
    "def qr_loss(y, x, q0=0.5, q1=0.841,q2=0.159):\n",
    "    y0 = outputs[:, :4, ...]\n",
    "    y1 = y[:,4:8,...]\n",
    "    y2 = y[:,8:,...]\n",
    "    custom_loss0 = torch.sum(torch.max(q0 * (y0 - x), (q0 - 1.0) * (y0 - x)))\n",
    "    custom_loss1 = torch.sum(torch.max(q1 * (y1 - x), (q1 - 1.0) * (y1 - x)))\n",
    "    custom_loss2 = torch.sum(torch.max(q2 * (y2 - x), (q2 - 1.0) * (y2 - x)))\n",
    "\n",
    "    #   torch.sum(torch.max(Q * (recon_x - x), (Q - 1) * (recon_x - x)))\n",
    "    return custom_loss0 + custom_loss1 + custom_loss2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters\n",
    "\n",
    "* run_id : set this to prevent overlapped saving of model and data\n",
    "\n",
    "* DO_MASK : Set to True if mask is to be applied while training\n",
    "* SET_VARIANCE : Set to True if variance is to be trained in loss function\n",
    "* PIXEL_DOWNSAMPLE : How much to scale down each axis. In other words, mm per pixel/voxel\n",
    "\n",
    "* max_epochs\n",
    "* val_interval : how frequently the validation code should be run\n",
    "* TRAIN_RATIO: proportion of total dataset to be used for training. Rest will be used for validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 23 # with 17, it was set variance False\n",
    "DO_MASK = True\n",
    "SET_VARIANCE = True\n",
    "max_epochs = 30000\n",
    "TRAIN_DATA_SIZE = 8\n",
    "BATCHSIZE_TRAIN = 2\n",
    "PIXEL_DOWNSAMPLE = [1, 1, 1]\n",
    "val_interval = 10\n",
    "TRAIN_RATIO = 0.8\n",
    "RANDOM_SEED = 0\n",
    "CONTINUE_TRAINING = False\n",
    "TRAIN_DATA_SHUFFLE = False\n",
    "root_dir = \"/scratch1/ajoshi/monai_data_1\"\n",
    "\n",
    "logger.info(\"PARAMETERS\\n-----------------\")\n",
    "logger.info(f\"run_id: {run_id}\")\n",
    "logger.info(f\"DO_MASK: {DO_MASK}\")\n",
    "logger.info(f\"SET_VARIANCE: {SET_VARIANCE}\")\n",
    "logger.info(f\"max_epochs: {max_epochs}\")\n",
    "logger.info(f\"TRAIN_DATA_SIZE: {TRAIN_DATA_SIZE}\")\n",
    "logger.info(f\"BATCHSIZE_TRAIN: {BATCHSIZE_TRAIN}\")\n",
    "logger.info(f\"PIXEL_DOWNSAMPLE: {PIXEL_DOWNSAMPLE}\")\n",
    "logger.info(f\"val_interval: {val_interval}\")\n",
    "logger.info(f\"TRAIN_RATIO: {TRAIN_RATIO}\")\n",
    "logger.info(f\"RANDOM_SEED: {RANDOM_SEED}\")\n",
    "logger.info(f\"CONTINUE_TRAINING: {CONTINUE_TRAINING}\")\n",
    "logger.info(f\"TRAIN_DATA_SHUFFLE: {TRAIN_DATA_SHUFFLE}\")\n",
    "logger.info(f\"root_dir: {root_dir}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if this is a notebook or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_notebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True  # Jupyter notebook or Jupyter QtConsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other types\n",
    "    except NameError:\n",
    "        return False  # Standard Python interpreter\n",
    "\n",
    "# Example usage\n",
    "if is_notebook():\n",
    "    logger.debug(\"This is a Jupyter Notebook.\")\n",
    "else:\n",
    "    logger.debug(\"This is a Python script (not a Jupyter Notebook).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDR2QhuhKX7O"
   },
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8uzoUh4uKX7P",
    "outputId": "8bb638f6-dd68-4ffd-84c2-2d30953b9190",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pdb\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    ")\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    LoadImage,\n",
    "    Resize,\n",
    "    NormalizeIntensity,\n",
    "    Orientation,\n",
    "    RandFlip,\n",
    "    RandScaleIntensity,\n",
    "    RandShiftIntensity,\n",
    "    RandSpatialCrop,\n",
    "    CenterSpatialCrop,\n",
    "    Spacing,\n",
    "    EnsureType,\n",
    "    EnsureChannelFirst,\n",
    ")\n",
    "from monai.metrics import MSEMetric\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from dataset import BrainMRIDataset\n",
    "\n",
    "# print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(root_dir, f\"run_{run_id}\")\n",
    "if os.path.exists(save_dir) and os.path.isdir(save_dir) and len(os.listdir(save_dir)) != 0:\n",
    "    logger.warning(f\"{save_dir} already exists. Avoid overwrite by updating run_id.\")\n",
    "    exit()\n",
    "else:\n",
    "    os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXLaSctjKX7Q"
   },
   "source": [
    "### Set deterministic training for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PeNCIs06KX7R"
   },
   "outputs": [],
   "source": [
    "set_determinism(seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Yob6T4xKX7S"
   },
   "source": [
    "## Setup transforms for training and validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1zn16zLKX7S"
   },
   "outputs": [],
   "source": [
    "crop_size = [64,64,64] # [224, 224, 144]\n",
    "resize_size = [64,64,64] #[crop_size[i]//PIXEL_DOWNSAMPLE[i] for i in range(len(crop_size))]\n",
    "\n",
    "train_transform = Compose(\n",
    "    [\n",
    "        # load 4 Nifti images and stack them together\n",
    "        LoadImage(),\n",
    "        EnsureChannelFirst(),\n",
    "        EnsureType(),\n",
    "        Orientation(axcodes=\"RAS\"),\n",
    "        #Spacing(\n",
    "        #    pixdim=(2.0, 2.0, 2.0),\n",
    "        #    mode=(\"bilinear\", \"nearest\"),\n",
    "        #),\n",
    "        Resize(spatial_size=resize_size, mode=\"nearest\"),\n",
    "        #RandSpatialCrop(roi_size=crop_size, random_size=False),\n",
    "        #RandFlip(prob=0.5, spatial_axis=0),\n",
    "        #RandFlip(prob=0.5, spatial_axis=1),\n",
    "        #RandFlip(prob=0.5, spatial_axis=2),\n",
    "        NormalizeIntensity(),#nonzero=True, channel_wise=True),\n",
    "        #RandScaleIntensity(factors=0.1, prob=1.0),\n",
    "        #RandShiftIntensity(offsets=0.1, prob=1.0),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = Compose(\n",
    "    [\n",
    "        LoadImage(),\n",
    "        EnsureChannelFirst(),\n",
    "        EnsureType(),\n",
    "        Orientation(axcodes=\"RAS\"),\n",
    "        #Spacing(\n",
    "        #    pixdim=(2.0, 2.0, 2.0),\n",
    "        #    mode=(\"bilinear\", \"nearest\"),\n",
    "        #),\n",
    "        Resize(spatial_size=resize_size, mode=\"nearest\"),\n",
    "        #CenterSpatialCrop(roi_size=crop_size), # added this because model was not handling 155dims\n",
    "        #Resize(spatial_size=resize_size, mode='nearest'),\n",
    "        NormalizeIntensity(),#nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dhVJ9qbVbGR"
   },
   "source": [
    "Create training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRkpcvfEHY7Q"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "all_dataset = BrainMRIDataset(\n",
    "    root_dir=root_dir,\n",
    "    seed = RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(all_dataset, [TRAIN_RATIO, 1-TRAIN_RATIO],\n",
    "                                          generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
    "\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = val_transform\n",
    "\n",
    "if TRAIN_DATA_SIZE:\n",
    "    train_dataset = Subset(train_dataset, list(range(TRAIN_DATA_SIZE)))\n",
    "    val_dataset = Subset(train_dataset, list(range(TRAIN_DATA_SIZE//4)))\n",
    "\n",
    "#train_data = CacheDataset(train_dataset)\n",
    "BATCHSIZE_VAL = BATCHSIZE_TRAIN\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCHSIZE_TRAIN, shuffle=TRAIN_DATA_SHUFFLE,\n",
    "    num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCHSIZE_VAL, shuffle=False, num_workers=8)\n",
    "\n",
    "logger.debug(\"Data loaded\")\n",
    "logger.debug(f\"Length of dataset: {len(train_dataset)}, {len(val_dataset)}\")\n",
    "logger.debug(f\"Batch-size: {BATCHSIZE_TRAIN}, {BATCHSIZE_VAL}\")\n",
    "logger.debug(f\"Length of data-loaders: {len(train_loader)}, {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXd4zV8DKX7S"
   },
   "source": [
    "## Check data shape and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnvWc-L1KX7S"
   },
   "outputs": [],
   "source": [
    "# pick one image from DecathlonDataset to visualize and check the 4 channels\n",
    "if is_notebook():\n",
    "    channels = [\"FLAIR\", \"T1w\", \"T1gd\", \"T2w\"]\n",
    "    val_data_example = val_dataset[0]['image']\n",
    "    _, im_length, im_width, im_height = val_data_example.shape\n",
    "    logger.debug(f\"image shape: {val_data_example.shape}\")\n",
    "    plt.figure(\"image\", (24, 6))\n",
    "    for i in range(4):\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.title(channels[i], fontsize=30)\n",
    "        brain_slice = val_data_example[i, :, :, im_height//2].detach().cpu().T\n",
    "        plt.xticks([0, im_width - 1], [0, im_width - 1], fontsize=15)\n",
    "        plt.yticks([0, im_length - 1], [0, im_length - 1], fontsize=15)\n",
    "        plt.imshow(brain_slice, cmap=\"gray\", vmax=1.0,vmin=-1.0)\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.ax.tick_params(labelsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3e3iR-hKX7T"
   },
   "source": [
    "## Create Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WScmgodkdmwU"
   },
   "source": [
    "**Define a 3D Unet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PeDy37CJdqCT"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = UNet(\n",
    "    spatial_dims=3, # 3D\n",
    "    in_channels=4,\n",
    "    out_channels=12, # we will output estimated mean and estimated std dev for all 4 image channels\n",
    "    channels=(4, 8, 16),\n",
    "    strides=(2, 2),\n",
    "    num_res_units=2\n",
    ").to(device)\n",
    "logger.debug(\"Model defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display the total number of parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "total_params = count_parameters(model)\n",
    "# logger.debug(f\"Total number of trainable parameters: {total_params}\")\n",
    "\n",
    "# Print the model architecture\n",
    "# logger.debug(f\"Model Architecture:\\n {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss (Guassian Likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def GaussianNLLLoss_custom(outputs, target):\n",
    "    # input is 4 channel images, outputs is 8 channel images\n",
    "\n",
    "    outputs_mean = outputs[:, :4, ...]\n",
    "    if not SET_VARIANCE:\n",
    "        log_std = torch.zeros_like(outputs_mean) # sigma = 1\n",
    "    else:\n",
    "        log_std = outputs[:, 4:, ...]\n",
    "        eps = np.log(1e-6)/2 # -6.9\n",
    "\n",
    "        # TODO: should the clamping be with or without autograd?\n",
    "        #log_std = log_std.clone()\n",
    "        #with torch.no_grad():\n",
    "        #    log_std.clamp_(min=eps)\n",
    "\n",
    "    cost1 = ((target - outputs_mean)**2.) / (2.*torch.exp(2.*log_std))\n",
    "    cost2 = log_std\n",
    "\n",
    "    return torch.mean(cost1 + cost2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmxkPH4GKX7T"
   },
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "loss_function = qr_loss #GaussianNLLLoss_custom\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
    "mse_metric = MSEMetric(reduction=\"mean\")\n",
    "\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "\n",
    "# define inference method\n",
    "def inference(input):\n",
    "    def _compute(input):\n",
    "        output = model(input)\n",
    "        return output\n",
    "\n",
    "    with torch.amp.autocast('cuda'):\n",
    "        return _compute(input)\n",
    "\n",
    "\n",
    "# use amp to accelerate training\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "# enable cuDNN benchmark\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_start = 1\n",
    "if CONTINUE_TRAINING:\n",
    "    load_dir = save_dir\n",
    "    model.load_state_dict(torch.load(os.path.join(load_dir, \"best_metric_model.pth\"), weights_only=True))\n",
    "    with open(os.path.join(load_dir, 'training_data.pkl'), 'rb') as f:\n",
    "        training_data = pickle.load(f)\n",
    "        epoch_loss_values = training_data['epoch_loss_values']\n",
    "        metric_values = training_data['metric_values']\n",
    "        ep_start = training_data['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8xDYlbRKX7T",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "\n",
    "logger.debug(\"Beginning training...\")\n",
    "total_start = time.time()\n",
    "for epoch in range(ep_start, max_epochs+1):\n",
    "    epoch_start_time = time.time()\n",
    "    logger.info(\"-\" * 10)\n",
    "    logger.info(f\"epoch {epoch}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    step_start = time.time()\n",
    "    for batch_data in train_loader:\n",
    "        data_loaded_time = time.time() - step_start\n",
    "        step += 1\n",
    "        inputs, mask, id = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"mask\"].to(device),\n",
    "            batch_data[\"id\"],\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            target = inputs.clone()\n",
    "            if DO_MASK:\n",
    "                inputs = inputs*~mask[:,:,None,None,None] - 1.0*mask[:,:,None,None,None]\n",
    "                num_masked = torch.sum(mask,axis=1)\n",
    "                \n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None and torch.isnan(param.grad).any():\n",
    "                    print(f\"NaN found in gradient of parameter: {name}\")\n",
    "                    exit()\n",
    "            outputs = model(inputs)\n",
    " \n",
    "            out_mask = torch.concatenate([mask[:,:,None,None,None],mask[:,:,None,None,None],mask[:,:,None,None,None]], axis=1)\n",
    "            print(out_mask.shape)\n",
    "            print(outputs.shape)\n",
    "            print(target.shape)\n",
    "            print(out_mask.shape)\n",
    "\n",
    "            loss = loss_function(outputs, target)#loss_function(outputs*out_mask, target*mask[:,:,None,None,None])\n",
    "            #loss = loss * torch.sum(num_masked)\n",
    "\n",
    "            if np.isnan(loss.item()):\n",
    "                logger.warning(\"nan value encountered (1)!\")\n",
    "                exit()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        if epoch > 10 and loss.item() > 1e5:\n",
    "            logger.warning(f\"large loss encountered: {loss.item()}!\")\n",
    "            exit()\n",
    "        if np.isnan(loss.item()):\n",
    "            logger.warning(\"nan value encountered (2)!\")\n",
    "            exit()\n",
    "        epoch_loss += loss.item()\n",
    "        logger.info(\n",
    "            f\"{step}/{len(train_loader)}\"\n",
    "            f\", train_loss: {loss.item():.4f}\"\n",
    "            f\", data-load time: {(data_loaded_time):.4f}\"\n",
    "            f\", total-step time: {(time.time() - step_start):.4f}\"\n",
    "        )\n",
    "        step_start = time.time()\n",
    "    lr_scheduler.step()\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    logger.info(f\"epoch {epoch} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if epoch % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_mask = (\n",
    "                    batch_data[\"image\"].to(device),\n",
    "                    batch_data[\"mask\"].to(device),\n",
    "                )\n",
    "                val_target = val_inputs.clone()\n",
    "                val_inputs = val_inputs*~val_mask[:,:,None,None,None]\n",
    "                val_outputs = inference(val_inputs)\n",
    "                val_output_main = val_outputs[:,:4,...]\n",
    "                mse_metric(y_pred=val_output_main, y=val_target)\n",
    "\n",
    "            metric = 1-mse_metric.aggregate().item()\n",
    "            metric_values.append(metric)\n",
    "            mse_metric.reset()\n",
    "\n",
    "            torch.save(\n",
    "                    model.state_dict(),\n",
    "                    os.path.join(save_dir, \"latest_model.pth\"),\n",
    "                )\n",
    "            logger.info(f\"saved latest model at epoch: {epoch}\")\n",
    "\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    os.path.join(save_dir, \"best_metric_model.pth\"),\n",
    "                )\n",
    "                logger.info(f\"saved new best metric model at epoch: {epoch}\")\n",
    "                \n",
    "            # Save the loss list\n",
    "            with open(os.path.join(save_dir, 'training_data.pkl'), 'wb') as f:\n",
    "                pickle.dump({\n",
    "                    'epoch': epoch,\n",
    "                    'epoch_loss_values': epoch_loss_values,\n",
    "                    'metric_values': metric_values,\n",
    "                }, f)\n",
    "            logger.info(\n",
    "                f\"current epoch: {epoch} current mean mse: {metric:.4f}\"\n",
    "                f\" best mean metric: {best_metric:.4f}\"\n",
    "                f\" at epoch: {best_metric_epoch}\"\n",
    "            )\n",
    "    logger.info(f\"time consuming of epoch {epoch} is: {(time.time() - epoch_start_time):.4f}\")\n",
    "total_time = time.time() - total_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnK_38mOKX7T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "logger.info(f\"Training time: {total_time//max_epochs:.1f}s/ep (total: {total_time//3600:.0f}h {(total_time//60)%60:.0f}m)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv-4",
   "language": "python",
   "name": "myenv-4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
