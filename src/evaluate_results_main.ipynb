{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from monai.data import DataLoader, decollate_batch\n",
    "from monai.utils import set_determinism\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from utils.dataset import BraTSDataset\n",
    "from utils.model import create_SegResNet, inference\n",
    "from utils.transforms import contr_syn_transform_scale as data_transform\n",
    "from utils.plot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logger import Logger\n",
    "logger = Logger(log_level='DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 0\n",
    "set_determinism(seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig = BraTSDataset(\n",
    "    version='2017',\n",
    "    section = 'validation',\n",
    "    seed = RANDOM_SEED,\n",
    "    transform = data_transform['val']\n",
    ")\n",
    "loader_orig = DataLoader(dataset_orig, batch_size=1, shuffle=False, num_workers=8)\n",
    "\n",
    "dataset_synth = BraTSDataset(\n",
    "    version='2017',\n",
    "    synth = True,\n",
    "    section = 'validation',\n",
    "    seed = RANDOM_SEED,\n",
    "    transform = data_transform['basic']\n",
    ")\n",
    "loader_synth = DataLoader(dataset_synth, batch_size=1, shuffle=False, num_workers=8)\n",
    "\n",
    "dataset_t1gd_mean = BraTSDataset( # dataset where t1gd is an avg of all t1gd: run_40\n",
    "    version='2017',\n",
    "    synth = True,\n",
    "    processed_path = '/scratch1/sachinsa/data/contr_generated/run_40',\n",
    "    section = 'validation',\n",
    "    seed = RANDOM_SEED,\n",
    "    transform = data_transform['basic']\n",
    ")\n",
    "\n",
    "logger.debug(\"Data loaded\")\n",
    "logger.debug(f\"Length of dataset: {len(dataset_orig)}, {len(dataset_synth)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_index = 0\n",
    "index_list = dataset_orig.get_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run from here!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ = index_list[id_index]\n",
    "id_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the slice (height index) at which Tumor Core is most present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_orig = dataset_orig.get_with_id(id_)['label']\n",
    "label_centroid =  find_centroid_3d(label_orig[0]) # centroid of TC (Tumor Core)\n",
    "h_index=label_centroid[-1]\n",
    "print(f\"h_index: {h_index}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ID: {id_}\")\n",
    "print(\"Original\")\n",
    "image_orig = dataset_orig.get_with_id(id_)['image']\n",
    "plot_brainmri(image_orig, channels=[\"FLAIR\", \"T1w\", \"T1Gd\", \"T2w\"], h_index=h_index, horiz=True, no_batch=True)\n",
    "\n",
    "image_synth = dataset_synth.get_with_id(id_)['image'][2:3]\n",
    "plot_brainmri(image_synth, channels=[\"T1Gd-synth\"], h_index=h_index, horiz=True, no_batch=True)\n",
    "\n",
    "image_mean = dataset_t1gd_mean.get_with_id(id_)['image'][2:3]\n",
    "plot_brainmri(image_mean, channels=[\"T1Gd-mean\"], h_index=h_index, horiz=True, no_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_img = image_orig.detach().cpu()\n",
    "print(f\"{brain_img.mean().item():.3f} Â± {brain_img.std().item():.3f} [{brain_img.min().item():.3f}, {brain_img.max().item():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label(label_orig, h_index=h_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.metrics import MSEMetric\n",
    "from utils.loss import mse_loss\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "mse_metric = MSEMetric(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_idx = 0\n",
    "mse_loss_combined = np.zeros(4)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for orig_data, synth_data in zip(loader_orig, loader_synth):\n",
    "        if run_idx > 5:break\n",
    "        orig_img, orig_id = (\n",
    "            orig_data[\"image\"][0].to(device),\n",
    "            orig_data[\"id\"][0].item(),\n",
    "        )\n",
    "        synth_img, synth_id = (\n",
    "            synth_data[\"image\"][0].to(device),\n",
    "            synth_data[\"id\"][0].item(),\n",
    "        )\n",
    "        assert(orig_id == synth_id)\n",
    "        synth_img_combined = torch.stack((\n",
    "                synth_img[2],\n",
    "                torch.zeros_like(orig_img[2]),\n",
    "                orig_img[1],\n",
    "                image_mean[0].to(device)\n",
    "            )\n",
    "        )\n",
    "        for i in range(4):\n",
    "            mse_loss_combined[i] += mse_loss(synth_img_combined[i], orig_img[2])\n",
    "        run_idx+=1\n",
    "    mse_loss_combined /= run_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate([\"synth\", \"zero\", \"T1w\", \"T1Gd-mean\"]):\n",
    "    print(f\"MSE {label}: {mse_loss_combined[i]:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
