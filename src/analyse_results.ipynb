{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To analyse the training result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 0 # set this to prevent overlapped saving of model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pdb\n",
    "import os\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MONAI_DATA_DIRECTORY\"] = \"/scratch1/sachinsa/monai_data_1\"\n",
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "if directory is not None:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(root_dir, f\"run_{run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss_values = np.load(os.path.join(save_dir, 'epoch_loss_values.npy')).tolist()\n",
    "metric_values = np.load(os.path.join(save_dir, 'metric_values.npy')).tolist()\n",
    "\n",
    "print(epoch_loss_values)\n",
    "print(metric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = len(epoch_loss_values)\n",
    "val_interval = len(epoch_loss_values)//len(metric_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_ratio = np.sum(np.isnan(epoch_loss_values))/len(epoch_loss_values)\n",
    "print(f\"{100*nan_ratio:.1f}% of values are nan!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (16, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss - log\")\n",
    "plt.plot(x, y, color=\"red\")\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "k = 2\n",
    "for zoom in [5,10]:\n",
    "    if len(x) > zoom:\n",
    "        plt.subplot(1, 3, k)\n",
    "        plt.title(\"Epoch Average Loss (Zoomed in)\")\n",
    "        x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "        y = epoch_loss_values\n",
    "        plt.xlabel(f\"epoch (from ep. {zoom})\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.plot(x[zoom:], y[zoom:], color=\"red\")\n",
    "    k += 1\n",
    "\n",
    "plt.figure(\"val\", (5,5))\n",
    "plt.title(\"Val Mean MSE\")\n",
    "x_val = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y_val = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x_val, y_val, color=\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    LoadImage,\n",
    "    NormalizeIntensity,\n",
    "    Orientation,\n",
    "    RandFlip,\n",
    "    RandScaleIntensity,\n",
    "    RandShiftIntensity,\n",
    "    RandSpatialCrop,\n",
    "    Spacing,\n",
    "    EnsureType,\n",
    "    EnsureChannelFirst,\n",
    ")\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    ")\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = UNet(\n",
    "    spatial_dims=3, # 3D\n",
    "    in_channels=4,\n",
    "    out_channels=8, # we will output estimated mean and estimated std dev for all 4 image channels\n",
    "    channels=(4, 8, 16),\n",
    "    strides=(2, 2),\n",
    "    num_res_units=2\n",
    ").to(device)\n",
    "\n",
    "VAL_AMP = True\n",
    "\n",
    "# define inference method\n",
    "def inference(input):\n",
    "    def _compute(input):\n",
    "        output = model(input)\n",
    "        return output\n",
    "\n",
    "    if VAL_AMP:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            return _compute(input)\n",
    "    else:\n",
    "        return _compute(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = Compose(\n",
    "    [\n",
    "        # load 4 Nifti images and stack them together\n",
    "        LoadImage(),\n",
    "        EnsureChannelFirst(),\n",
    "        EnsureType(),\n",
    "        Orientation(axcodes=\"RAS\"),\n",
    "        Spacing(\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        RandSpatialCrop(roi_size=[224, 224, 144], random_size=False),\n",
    "        RandFlip(prob=0.5, spatial_axis=0),\n",
    "        RandFlip(prob=0.5, spatial_axis=1),\n",
    "        RandFlip(prob=0.5, spatial_axis=2),\n",
    "        NormalizeIntensity(nonzero=True, channel_wise=True),\n",
    "        RandScaleIntensity(factors=0.1, prob=1.0),\n",
    "        RandShiftIntensity(offsets=0.1, prob=1.0),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainMRIDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = os.path.join(root_dir, \"Task01_BrainTumour\")\n",
    "        json_file_path = os.path.join(self.root_dir, \"dataset.json\")\n",
    "        with open(json_file_path, 'r') as file:\n",
    "            data_json = json.load(file)\n",
    "\n",
    "        self.image_filenames = data_json['training']\n",
    "\n",
    "        np.random.seed(0)\n",
    "        self.seq_mask = np.random.rand(len(self.image_filenames), 4) < 0.2\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.normpath(os.path.join(self.root_dir,self.image_filenames[idx]['image']))\n",
    "        mask = self.seq_mask[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(img_name)\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "\n",
    "        return {\"image\":image, \"mask\":mask}\n",
    "    \n",
    "\n",
    "\n",
    "sample_ds = BrainMRIDataset(\n",
    "    root_dir=root_dir,\n",
    "    transform=train_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(save_dir, \"best_metric_model.pth\")))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # select one image to evaluate and visualize the model output\n",
    "    val_input = sample_ds[6][\"image\"].unsqueeze(0).to(device)\n",
    "    mask_indices = [True, False, False, False]\n",
    "    val_input[:, mask_indices, ...] = 0\n",
    "    val_output = inference(val_input)\n",
    "    # val_output = post_trans(val_output[0])\n",
    "    plt.figure(\"image\", (24, 6))\n",
    "    for i in range(4):\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.title(f\"image channel {i}\")\n",
    "        plt.imshow(val_input[0, i, :, :, 70].detach().cpu(), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    # visualize the 3 channels model output corresponding to this image\n",
    "    plt.figure(\"output mean\", (24, 6))\n",
    "    for i in range(4):\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.title(f\"output channel {i}\")\n",
    "        plt.imshow(val_output[0, i, :, :, 70].detach().cpu(), cmap=\"gray\")\n",
    "\n",
    "    plt.figure(\"output std\", (24, 6))\n",
    "    for i in range(4):\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.title(f\"output channel {i}\")\n",
    "        plt.imshow(val_output[0, i+4, :, :, 70].detach().cpu(), cmap=\"gray\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv-4",
   "language": "python",
   "name": "myenv-4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
