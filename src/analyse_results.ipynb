{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To analyse synthesis and uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = 22 # set this to prevent overlapped saving of model and data\n",
    "RANDOM_SEED = 0\n",
    "ROOT_DIR = \"/scratch1/sachinsa/cont_syn\"\n",
    "QR_REGRESSION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pdb\n",
    "import numpy as np\n",
    "import pickle\n",
    "from utils.logger import Logger\n",
    "\n",
    "logger = Logger(log_level='DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = os.path.join(ROOT_DIR, f\"run_{RUN_ID}\")\n",
    "fig_save_dir = os.path.join(\"..\", \"figs\", f\"run_{RUN_ID}\")\n",
    "os.makedirs(fig_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(load_dir, 'training_info.pkl'), 'rb') as f:\n",
    "    training_info = pickle.load(f)\n",
    "    epoch_loss_values = training_info['epoch_loss_values']\n",
    "    metric_values = training_info['metric_values']\n",
    "\n",
    "logger.info(\"PARAMETERS\\n-----------------\")\n",
    "logger.info(f\"RUN_ID: {RUN_ID}\")\n",
    "logger.info(f\"QR_REGRESSION: {QR_REGRESSION}\")\n",
    "logger.info(f\"ROOT_DIR: {ROOT_DIR}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = len(epoch_loss_values)\n",
    "val_interval = len(epoch_loss_values)//len(metric_values)\n",
    "print(\"Max epochs:\", max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_TRAINING_FIGURE = True\n",
    "\n",
    "if not MULTI_TRAINING_FIGURE:\n",
    "    plt.figure(\"train\", (6, 4))\n",
    "    x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "    y = epoch_loss_values\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss - log\")\n",
    "    plt.yscale('log')\n",
    "    plt.plot(x, y, color=\"red\")\n",
    "    plt.title(\"Training: Gaussian Log Likelihood Loss\", fontsize=25)\n",
    "    plt.savefig(os.path.join(fig_save_dir, \"train_plot.png\"), facecolor='white')\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.figure(\"train\", (18, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "    y = epoch_loss_values\n",
    "    plt.xlabel(\"epoch\", fontsize=15)\n",
    "    plt.ylabel(\"loss\", fontsize=15)\n",
    "    # plt.ylabel(\"loss - log\", fontsize=15)\n",
    "    # plt.yscale('log')\n",
    "    plt.plot(x, y, color=\"red\")\n",
    "    plt.suptitle(\"Training: GLL Loss\", fontsize=20)\n",
    "\n",
    "    k = 2\n",
    "    for zoom in [20, 100]:\n",
    "        if len(x) > zoom:\n",
    "            plt.subplot(1, 3, k)\n",
    "            x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "            y = epoch_loss_values\n",
    "            plt.ylabel(\"loss\", fontsize=15)\n",
    "            plt.xlabel(f\"epoch (from ep. {zoom})\", fontsize=15)\n",
    "            \n",
    "            plt.plot(x[zoom:], y[zoom:], color=\"red\")\n",
    "        k += 1\n",
    "    plt.savefig(os.path.join(fig_save_dir, \"train_plot.png\"), facecolor='white')\n",
    "    plt.show()\n",
    "\n",
    "plt.figure(\"val\", (6, 4))\n",
    "plt.title(\"Validation: 1-MSE\", fontsize=20)\n",
    "x_val = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y_val = metric_values\n",
    "plt.xlabel(\"epoch\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.plot(x_val, y_val, color=\"green\")\n",
    "plt.savefig(os.path.join(fig_save_dir, \"val_plot.png\"), facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from utils.model import create_UNet3D, inference\n",
    "from utils.transforms import contr_syn_transform_3\n",
    "from utils.dataset import BraTSDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "out_channels = 12 if QR_REGRESSION else 8\n",
    "model = create_UNet3D(out_channels, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = BraTSDataset(\n",
    "    version='2017',\n",
    "    section = 'validation',\n",
    "    seed = RANDOM_SEED,\n",
    "    transform = contr_syn_transform_3['val']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(os.path.join(load_dir, 'best_checkpoint.pth'), weights_only=True)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "channels = [\"FLAIR\", \"T1w\", \"T1Gd\", \"T2w\"]\n",
    "input_mask = [True, False, True, False]\n",
    "\n",
    "with torch.no_grad():\n",
    "    this_input = val_dataset.get_random()\n",
    "    input_image = this_input[\"image\"].unsqueeze(0).to(device)\n",
    "    input_image_copy = input_image.clone()\n",
    "    input_image_copy[:, input_mask, ...] = 0\n",
    "    this_output = inference(input_image_copy, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, im_length, im_width, im_height = input_image.shape\n",
    "h_index = im_height//2\n",
    "extremes = { # to map vmin, vmax\n",
    "    \"FLAIR\": {\n",
    "        \"input\": [3, -3],\n",
    "        \"q0\": [3, -3],\n",
    "        \"q1\": [2, 0],\n",
    "        \"q2\": [3, -3],\n",
    "        \"q3\": [1, 0],\n",
    "    },\n",
    "    \"T1w\": {\n",
    "        \"input\": [3, -3],\n",
    "        \"q0\": [3, -3],\n",
    "        \"q1\": [3, 0],\n",
    "        \"q2\": [5, -5],\n",
    "        \"q3\": [1, 0],\n",
    "    },\n",
    "    \"T1Gd\": {\n",
    "        \"input\": [3, -3],\n",
    "        \"q0\": [3, -3],\n",
    "        \"q1\": [2, 0],\n",
    "        \"q2\": [4, -4],\n",
    "        \"q3\": [1, 0],\n",
    "    },\n",
    "    \"T2w\": {\n",
    "        \"input\": [4, -3],\n",
    "        \"q0\": [4, -3],\n",
    "        \"q1\": [3, 0],\n",
    "        \"q2\": [4, -4],\n",
    "        \"q3\": [1, 0],\n",
    "    }\n",
    "}\n",
    "\n",
    "def plot_brain(index, label):\n",
    "    start_index = None\n",
    "    row_title = \"\"\n",
    "    this_input_sub = input_image[0, :, :, :, h_index]\n",
    "    this_output_sub = this_output[0, :, :, :, h_index]\n",
    "    nc = len(channels)\n",
    "\n",
    "    if label == \"input\":\n",
    "        start_index = 0*nc\n",
    "        row_title = \"Input\"\n",
    "        brain_slice = this_input_sub[index]\n",
    "    elif label == \"mean\":\n",
    "        start_index = 1*nc\n",
    "        row_title = \"Output: \" + r\"$\\mu$\"\n",
    "        brain_slice = this_output_sub[index]\n",
    "    elif label == \"var\":\n",
    "        start_index = 2*nc\n",
    "        row_title = \"Output: \" + r\"$\\sigma$\" + \"\"\n",
    "        brain_slice = this_output_sub[index+4]\n",
    "        brain_slice = torch.exp(brain_slice)\n",
    "        var_threshold = torch.quantile(brain_slice.float(), 0.95).item()\n",
    "        brain_slice[brain_slice >= var_threshold] = var_threshold\n",
    "    elif label == \"q0\":\n",
    "        start_index = 1*nc\n",
    "        row_title = \"Output: \" + \"q0\"\n",
    "        brain_slice = this_output_sub[index]\n",
    "    elif label == \"q1\":\n",
    "        start_index = 2*nc\n",
    "        row_title = \"Output: \" + r\"qH-qL\" + \"\"\n",
    "        brain_slice = 0.5*(this_output_sub[index+2*nc] - this_output_sub[index+1*nc])\n",
    "    elif label == \"q2\":\n",
    "        start_index = 3*nc\n",
    "        row_title = \"Output: \" + r\"qH\" + \"\"\n",
    "        brain_slice = this_output_sub[index+2*nc]\n",
    "    elif label == \"q3\":\n",
    "        start_index = 4*nc\n",
    "        row_title = \"Outlier\"\n",
    "        lower_slice = this_input_sub[index] < this_output_sub[index+nc]\n",
    "        upper_slice = this_input_sub[index] > this_output_sub[index+2*nc]\n",
    "        brain_slice = torch.logical_or(lower_slice, upper_slice)\n",
    "    num_rows = 5 if QR_REGRESSION else 3\n",
    "    \n",
    "    plt.subplot(num_rows, 4, start_index + index + 1)\n",
    "\n",
    "    col_title = channels[index]\n",
    "    col_title = f\"{col_title} (X)\" if input_mask[index] else col_title\n",
    "    if label == \"input\":\n",
    "        plt.title(col_title, fontsize=30)\n",
    "\n",
    "    brain_slice = brain_slice.detach().cpu().T\n",
    "\n",
    "    CLAMP_VIS = False # Clamp visualization\n",
    "    if CLAMP_VIS:\n",
    "        PERCENTILE = True\n",
    "        if not PERCENTILE:\n",
    "            extr = extremes[channels[index]][label]\n",
    "        else:\n",
    "            extr = [np.percentile(brain_slice, 1), np.percentile(brain_slice, 99)]\n",
    "        plt.imshow(brain_slice, cmap=\"gray\",vmin=extr[0],vmax=extr[1])\n",
    "    else:\n",
    "        plt.imshow(brain_slice, cmap=\"gray\")\n",
    "\n",
    "    plt.xlabel('')\n",
    "    if index == 0:\n",
    "        plt.ylabel(row_title, fontsize=30)\n",
    "\n",
    "    plt.xticks([im_width - 1], [im_width], fontsize=15)\n",
    "    plt.yticks([im_length - 1], [im_length], fontsize=15)\n",
    "    cbar = plt.colorbar(shrink=0.7)\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "plt.figure(\"image\", (24, 18))\n",
    "for i in range(4):\n",
    "    plot_brain(i, \"input\")\n",
    "if QR_REGRESSION:\n",
    "    for i in range(4):\n",
    "        plot_brain(i, \"q0\")\n",
    "    for i in range(4):\n",
    "        plot_brain(i, \"q1\")\n",
    "    # for i in range(4):\n",
    "    #     plot_brain(i, \"q2\")\n",
    "    # for i in range(4):\n",
    "    #     plot_brain(i, \"q3\")\n",
    "else:\n",
    "    for i in range(4):\n",
    "        plot_brain(i, \"mean\")\n",
    "    for i in range(4):\n",
    "        plot_brain(i, \"var\")\n",
    "\n",
    "plt.suptitle(f\"BRATS_{this_input['id']} (h={h_index}/{im_height})\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(fig_save_dir, \"model_inference.png\"), facecolor='white')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv-4",
   "language": "python",
   "name": "myenv-4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
