{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To save uncertainty results for downstream task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = 22\n",
    "RANDOM_SEED = 0\n",
    "ROOT_DIR = \"/scratch1/sachinsa/cont_syn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import pdb\n",
    "import numpy as np\n",
    "from utils.logger import Logger\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.model import create_UNet3D, inference\n",
    "from utils.transforms import contr_syn_transform_3 as data_transform\n",
    "from utils.dataset import BraTSDataset\n",
    "\n",
    "logger = Logger(log_level='DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = os.path.join(ROOT_DIR, f\"run_{RUN_ID}\")\n",
    "save_dir = os.path.join('/scratch1/sachinsa/data/contr_generated', f\"run_{RUN_ID}_mixed\")\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = create_UNet3D(out_channels=12, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_dataset = BraTSDataset(\n",
    "#     version='2017',\n",
    "#     section='all',\n",
    "#     seed = RANDOM_SEED,\n",
    "#     transform = contr_syn_transform_3['val']\n",
    "# )\n",
    "# all_loader = DataLoader(all_dataset, batch_size=1, shuffle=False, num_workers=8)\n",
    "\n",
    "dataset_orig = BraTSDataset(\n",
    "    version='2017',\n",
    "    processed = False,\n",
    "    section = 'all',\n",
    "    seed = RANDOM_SEED,\n",
    "    transform = data_transform['val']\n",
    ")\n",
    "loader_orig = DataLoader(dataset_orig, batch_size=1, shuffle=False, num_workers=8)\n",
    "\n",
    "dataset_median = BraTSDataset(\n",
    "    version='2017',\n",
    "    processed = True,\n",
    "    section = 'all',\n",
    "    seed = RANDOM_SEED,\n",
    "    transform = data_transform['basic']\n",
    ")\n",
    "loader_median = DataLoader(dataset_median, batch_size=1, shuffle=False, num_workers=8)\n",
    "\n",
    "logger.debug(\"Data loaded\")\n",
    "logger.debug(f\"Length of dataset: {len(dataset_orig)}, {len(dataset_median)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load masks\n",
    "mask_root_dir = \"/scratch1/sachinsa/data/masks/brats2017\"\n",
    "train_mask_df = pd.read_csv(os.path.join(mask_root_dir, \"train_mask.csv\"), index_col=0)\n",
    "val_mask_df = pd.read_csv(os.path.join(mask_root_dir, \"val_mask.csv\"), index_col=0)\n",
    "all_mask_df = pd.concat([train_mask_df, val_mask_df], axis=0)\n",
    "all_mask_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(os.path.join(load_dir, 'best_checkpoint.pth'), weights_only=True)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# model.eval()\n",
    "channels = [\"FLAIR\", \"T1w\", \"T1Gd\", \"T2w\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "with torch.no_grad():\n",
    "    for this_data, median_data in zip(loader_orig,loader_median):\n",
    "        # i+=1\n",
    "        # if i>2:break\n",
    "        this_inputs, this_ids = (\n",
    "            this_data[\"image\"].to(device),\n",
    "            this_data[\"id\"],\n",
    "        )\n",
    "        this_mask = torch.from_numpy(all_mask_df.loc[this_ids.tolist(), :].values).to(device)[:,:,None,None,None]\n",
    "        this_saved_median = median_data[\"image\"][:,:4,...].to(device)\n",
    "        this_inputs = this_inputs*~this_mask\n",
    "        this_saved_median = this_saved_median*this_mask\n",
    "        this_mixed = this_inputs + this_saved_median\n",
    "        \n",
    "        mri_array = this_mixed[0].detach().permute(1, 2, 3, 0).cpu().numpy()\n",
    "        nifti_img = nib.Nifti1Image(mri_array,affine=np.eye(4))\n",
    "        output_filename = os.path.join(save_dir, f'BRATS_{this_ids[0]}.nii.gz')\n",
    "        print(output_filename)\n",
    "        nib.save(nifti_img, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(this_mask.squeeze())\n",
    "# this_id = this_data[\"id\"].item()\n",
    "# this_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# print(this_mixed.shape)\n",
    "\n",
    "# this_target = this_inputs\n",
    "\n",
    "# h_index = 77\n",
    "# c_index = 1 # channel\n",
    "# channels = [\"FLAIR\", \"T1w\", \"T1Gd\", \"T2w\"]\n",
    "# print(f\"Channel: {channels[c_index]}\")\n",
    "# print(f\"ID: {this_id}\")\n",
    "# brain_slice = this_target.detach().cpu().numpy()\n",
    "# brain_slice = brain_slice[0,c_index,:,:,h_index].T\n",
    "# plt.figure()\n",
    "# plt.title(f'Original: {this_id}')\n",
    "# plt.imshow(brain_slice, cmap='gray')\n",
    "# plt.colorbar()\n",
    "\n",
    "# brain_slice = this_saved_median.detach().cpu().numpy()\n",
    "# brain_slice = brain_slice[0,c_index,:,:,h_index].T\n",
    "# print(brain_slice.mean(), brain_slice.min(), brain_slice.max())\n",
    "# plt.figure()\n",
    "# plt.title(f'Saved Median: {this_id}')\n",
    "# plt.imshow(brain_slice, cmap='gray')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     for this_data in all_loader:\n",
    "#         this_inputs, this_ids = (\n",
    "#             this_data[\"image\"].to(device),\n",
    "#             this_data[\"id\"],\n",
    "#         )\n",
    "#         this_mask = torch.from_numpy(all_mask_df.loc[this_ids.tolist(), :].values).to(device)\n",
    "#         this_target = this_inputs.clone()\n",
    "#         this_inputs = this_inputs*~this_mask[:,:,None,None,None]\n",
    "#         this_outputs = inference(this_inputs, model)\n",
    "        \n",
    "#         mri_array = this_outputs[0].detach().permute(1, 2, 3, 0).cpu().numpy()\n",
    "#         nifti_img = nib.Nifti1Image(mri_array,affine=np.eye(4))\n",
    "#         output_filename = os.path.join(save_dir, f'BRATS_{this_ids[0]}.nii.gz')\n",
    "#         print(output_filename)\n",
    "#         nib.save(nifti_img, output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv-4",
   "language": "python",
   "name": "myenv-4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
