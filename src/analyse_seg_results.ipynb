{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To analyse the brain segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = 1\n",
    "ROOT_DIR = \"/scratch1/sachinsa/brats_seg\"\n",
    "DATA_ROOT_DIR = \"/scratch1/sachinsa/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pdb\n",
    "import numpy as np\n",
    "import pickle\n",
    "from utils.logger import Logger\n",
    "\n",
    "logger = Logger(log_level='DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = os.path.join(ROOT_DIR, f\"run_{RUN_ID}\")\n",
    "fig_save_dir = os.path.join(\"..\", \"figs\", f\"run_{RUN_ID}\")\n",
    "os.makedirs(fig_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(load_dir, 'training_info.pkl'), 'rb') as f:\n",
    "    training_info = pickle.load(f)\n",
    "    epoch_loss_values = training_info['epoch_loss_values']\n",
    "    metric_values = training_info['metric_values']\n",
    "    metric_values_tc = training_info['metric_values_tc']\n",
    "    metric_values_wt = training_info['metric_values_wt']\n",
    "    metric_values_et = training_info['metric_values_et']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = len(epoch_loss_values)\n",
    "val_interval = len(epoch_loss_values)//len(metric_values)\n",
    "print(max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"red\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"green\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(\"train\", (18, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Val Mean Dice TC\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_tc))]\n",
    "y = metric_values_tc\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"blue\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Val Mean Dice WT\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_wt))]\n",
    "y = metric_values_wt\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"brown\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Val Mean Dice ET\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values_et))]\n",
    "y = metric_values_et\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, color=\"purple\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from monai.apps import DecathlonDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, decollate_batch\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import SegResNet\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "from tqdm import tqdm\n",
    "from utils.transforms import tumor_seg_transform as data_transform\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = SegResNet(\n",
    "    blocks_down=[1, 2, 2, 4],\n",
    "    blocks_up=[1, 1, 1],\n",
    "    init_filters=16,\n",
    "    in_channels=4,\n",
    "    out_channels=3,\n",
    "    dropout_prob=0.2,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
    "\n",
    "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "\n",
    "def inference(input):\n",
    "    def _compute(input):\n",
    "        return sliding_window_inference(\n",
    "            inputs=input,\n",
    "            roi_size=(240, 240, 160),\n",
    "            sw_batch_size=1,\n",
    "            predictor=model,\n",
    "            overlap=0.5,\n",
    "        )\n",
    "\n",
    "    with torch.amp.autocast('cuda'):\n",
    "        return _compute(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = DecathlonDataset(\n",
    "    root_dir=DATA_ROOT_DIR,\n",
    "    task=\"Task01_BrainTumour\",\n",
    "    transform=data_transform['val'],\n",
    "    section=\"validation\",\n",
    "    download=False,\n",
    "    cache_rate=0.0,\n",
    "    num_workers=8,#4,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(os.path.join(load_dir, 'best_checkpoint.pth'), weights_only=True)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_index = 6\n",
    "with torch.no_grad():\n",
    "    # select one image to evaluate and visualize the model output\n",
    "    input_image = val_ds[val_index][\"image\"].unsqueeze(0).to(device)\n",
    "    roi_size = (128, 128, 64)\n",
    "    sw_batch_size = 4\n",
    "    this_output = inference(input_image)\n",
    "    this_output = post_trans(this_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, im_length, im_width, im_height = input_image.shape\n",
    "im_length, im_width, im_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, im_length, im_width, im_height = input_image.shape\n",
    "h_index = im_height//2\n",
    "label_list = [\"TC\", \"WT\", \"ET\"]\n",
    "channels = [\"FLAIR\", \"T1w\", \"T1gd\", \"T2w\"]\n",
    "\n",
    "def plot_brain(index, label):\n",
    "    if label == \"ground_truth\":\n",
    "        start_index = 0\n",
    "        brain_slice = val_ds[val_index][\"label\"]\n",
    "        title = \"Ground Truth\"\n",
    "    elif label == \"prediction\":\n",
    "        start_index = len(label_list)\n",
    "        brain_slice = this_output\n",
    "        title = \"Prediction\"\n",
    "\n",
    "    brain_slice = brain_slice[index, :, :, 70].detach().cpu().T\n",
    "    plt.subplot(2, 3, start_index + index + 1)\n",
    "    plt.title(label_list[index], fontsize=30)\n",
    "    if index == 0:\n",
    "        plt.ylabel(title, fontsize=30)\n",
    "    plt.xticks([0, im_width - 1], [0, im_width - 1], fontsize=15)\n",
    "    plt.yticks([0, im_length - 1], [0, im_length - 1], fontsize=15)\n",
    "    plt.imshow(brain_slice, cmap=\"gray\")\n",
    "\n",
    "\n",
    "plt.figure(\"image\", (24, 6))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.title(channels[i], fontsize=30)\n",
    "    if i == 0:\n",
    "        plt.ylabel(\"Input\", fontsize=30)\n",
    "    plt.xticks([0, im_width - 1], [0, im_width - 1], fontsize=15)\n",
    "    plt.yticks([0, im_length - 1], [0, im_length - 1], fontsize=15)\n",
    "    plt.imshow(val_ds[val_index][\"image\"][i, :, :, 70].detach().cpu().T, cmap=\"gray\")\n",
    "plt.suptitle(f\"{val_ds.get_indices()[val_index]} (h={h_index}/{im_height})\", fontsize=20)\n",
    "plt.show()\n",
    "    \n",
    "plt.figure(\"label\", (18, 12))\n",
    "for i in range(len(label_list)):\n",
    "    plot_brain(i, \"ground_truth\")\n",
    "for i in range(len(label_list)):\n",
    "    plot_brain(i, \"prediction\")\n",
    "plt.suptitle(f\"{val_ds.get_indices()[val_index]} (h={h_index}/{im_height})\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # i = 0\n",
    "    for val_data in val_loader:\n",
    "        # i += 1\n",
    "        # if i > 4: break\n",
    "        val_inputs, val_labels = (\n",
    "            val_data[\"image\"].to(device),\n",
    "            val_data[\"label\"].to(device),\n",
    "        )\n",
    "        val_outputs = inference(val_inputs)\n",
    "        val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "        dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "        dice_metric_batch(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "    metric = dice_metric.aggregate().item()\n",
    "    metric_batch_org = dice_metric_batch.aggregate()\n",
    "\n",
    "    dice_metric.reset()\n",
    "    dice_metric_batch.reset()\n",
    "\n",
    "metric_tc, metric_wt, metric_et = metric_batch_org[0].item(), metric_batch_org[1].item(), metric_batch_org[2].item()\n",
    "\n",
    "print(f\"metric: {metric:.3f}\")\n",
    "print(f\"metric_tc: {metric_tc:.3f}\")\n",
    "print(f\"metric_wt: {metric_wt:.3f}\")\n",
    "print(f\"metric_et: {metric_et:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv-4",
   "language": "python",
   "name": "myenv-4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
